_target_: cargpt.models.control_transformer.ControlTransformer
_recursive_: false
input_transforms:
  - select: [image]
    apply:
      # NOTE/PERF: https://pytorch.org/vision/main/transforms.html#performance-considerations
      _target_: torch.compile
      model:
        _target_: torch.nn.Sequential
        _args_:
          - _target_: einops.layers.torch.Rearrange
            pattern: "... h w c -> ... c h w"
          - _target_: cargpt.utils.transforms.ApplyMask
            mask_path: /nas/drives/yaak/data/Niro115-HQ/mask_576x320.json
          - _target_: torchvision.transforms.v2.CenterCrop
            size: [320, 576]
          - _target_: torchvision.transforms.v2.ToDtype
            scale: true
            dtype:
              _target_: hydra.utils.get_object
              path: torch.float32
          - _target_: torchvision.transforms.v2.Normalize
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]

episode_builder:
  _target_: cargpt.components.episode.EpisodeBuilder
  _recursive_: true
  timestep:
    _target_: cargpt.components.episode.Timestep.build
    _args_:
      - [observation, image, cam_front_left]
      - [observation, continuous, speed]
      - [observation, discrete, turn_signal]
      - [special, observation_summary]
      - [special, observation_history]
      - [action, continuous, gas_pedal]
      - [action, continuous, brake_pedal]
      - [action, continuous, steering_angle]
      - [special, action_summary]
      - [special, depth_summary]
      - [special, pose_summary]
  special_tokens:
    observation_summary: 0
    observation_history: 1
    action_summary: 2
    depth_summary: 3
    pose_summary: 4

  tokenizers:
    _target_: cargpt.utils.ModuleDict
    image:
      _target_: cargpt.components.nn.Identity
    continuous:
      speed:
        _target_: cargpt.components.norm.UniformBinner
        range: [0.0, 130.0]
        bins: 512
      gas_pedal:
        _target_: cargpt.components.norm.UniformBinner
        range: [0.0, 1.0]
        bins: 512
      brake_pedal:
        _target_: cargpt.components.norm.UniformBinner
        range: [0.0, 1.0]
        bins: 512
      steering_angle:
        _target_: cargpt.components.norm.UniformBinner
        range: [-1.0, 1.0]
        bins: 512
    discrete:
      turn_signal:
        _target_: cargpt.components.nn.Identity
  embeddings:
    _target_: cargpt.utils.ModuleDict
    image:
      _target_: torch.nn.Sequential
      _args_:
        - _target_: cargpt.components.resnet.ResnetBackbone
          resnet:
            _target_: torchvision.models.resnet50
            weights: IMAGENET1K_V1
          freeze: False

        - _target_: cargpt.utils.ModuleDict
          "0":
            _target_: cargpt.components.nn.Identity
          "1":
            _target_: cargpt.components.nn.Identity
          "2":
            _target_: cargpt.components.nn.Identity
          "3":
            _target_: cargpt.components.nn.Identity
          "4":
            _target_: einops.layers.torch.Rearrange
            pattern: '... c h w -> ... (h w) c'
    continuous:
      speed:
        _target_: cargpt.components.nn.Embedding
        num_embeddings: ${model.episode_builder.tokenizers.continuous.speed.bins}
        embedding_dim: ${vars.embedding_dim}
      gas_pedal:
        _target_: cargpt.components.nn.Embedding
        num_embeddings: ${model.episode_builder.tokenizers.continuous.gas_pedal.bins}
        embedding_dim: ${vars.embedding_dim}
      brake_pedal:
        _target_: cargpt.components.nn.Embedding
        num_embeddings: ${model.episode_builder.tokenizers.continuous.brake_pedal.bins}
        embedding_dim: ${vars.embedding_dim}
      steering_angle:
        _target_: cargpt.components.nn.Embedding
        num_embeddings: ${model.episode_builder.tokenizers.continuous.steering_angle.bins}
        embedding_dim: ${vars.embedding_dim}
    discrete:
      turn_signal:
        _target_: cargpt.components.nn.Embedding
        num_embeddings: 3
        embedding_dim: ${vars.embedding_dim}
    special:
      _target_: cargpt.components.nn.Embedding
      num_embeddings: 5
      embedding_dim: ${vars.embedding_dim}
  position_encoding:
    _target_: cargpt.utils.ModuleDict
    image:
      patch:
        row:
          _target_: cargpt.components.nn.Embedding
          num_embeddings: 10
          embedding_dim: ${vars.embedding_dim}
        col:
          _target_: cargpt.components.nn.Embedding
          num_embeddings: 18
          embedding_dim: ${vars.embedding_dim}
    observations:
      _target_: cargpt.components.nn.Embedding
      num_embeddings: 182
      embedding_dim: ${vars.embedding_dim}
    actions:
      _target_: cargpt.components.nn.Embedding
      num_embeddings: 1
      embedding_dim: ${vars.embedding_dim}
    special:
      _target_: cargpt.components.nn.Embedding
      num_embeddings: 1
      embedding_dim: ${vars.embedding_dim}
    timestep:
      _target_: cargpt.components.nn.Embedding
      num_embeddings: ${vars.data.test.clip_length}
      embedding_dim: ${vars.embedding_dim}
encoder:
  _target_: cargpt.components.llm.xFormerEncoder
  config:
    _target_: xformers.factory.xFormerEncoderConfig
    reversible: True
    num_layers: ${vars.encoder.num_layers}
    dim_model: ${vars.embedding_dim}
    residual_norm_style: pre
    multi_head_config:
      dim_model: ${vars.embedding_dim}
      num_heads: ${vars.encoder.num_heads}
      residual_dropout: 0.1
      attention:
        name: scaled_dot_product
        dropout: 0.1
        causal: False
    feedforward_config:
      name: MLPGLU
      dropout: 0.1
      activation: gelu
      hidden_layer_multiplier: 1
objectives:
  _target_: cargpt.utils.ModuleDict
  # inverse_dynamics:
  #   _target_: cargpt.components.objectives.InverseDynamicsPredictionObjective
  #   heads:
  #     _target_: cargpt.utils.ModuleDict
  #     continuous:
  #       gas_pedal:
  #         _target_: torch.nn.Linear
  #         in_features:
  #           _target_: operator.mul
  #           _args_:
  #             - 2
  #             - ${vars.embedding_dim}
  #         out_features: ${model.episode_builder.tokenizers.continuous.gas_pedal.bins}
  #         bias: False
  #       brake_pedal:
  #         _target_: torch.nn.Linear
  #         in_features:
  #           _target_: operator.mul
  #           _args_:
  #             - 2
  #             - ${vars.embedding_dim}
  #         out_features: ${model.episode_builder.tokenizers.continuous.brake_pedal.bins}
  #         bias: False
  #       steering_angle:
  #         _target_: torch.nn.Linear
  #         in_features:
  #           _target_: operator.mul
  #           _args_:
  #             - 2
  #             - ${vars.embedding_dim}
  #         out_features: ${model.episode_builder.tokenizers.continuous.steering_angle.bins}
  #         bias: False
  #   targets:
  #     continuous:
  #       gas_pedal:
  #         _target_: cargpt.components.episode.Episode.get
  #         _partial_: true
  #         key: ["tokenized", "continuous", "gas_pedal"]
  #       brake_pedal:
  #         _target_: cargpt.components.episode.Episode.get
  #         _partial_: true
  #         key: ["tokenized", "continuous", "brake_pedal"]
  #       steering_angle:
  #         _target_: cargpt.components.episode.Episode.get
  #         _partial_: true
  #         key: ["tokenized", "continuous", "steering_angle"]
  #   losses:
  #     _target_: cargpt.utils.ModuleDict
  #     continuous:
  #       gas_pedal:
  #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
  #       brake_pedal:
  #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
  #       steering_angle:
  #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
  forward_dynamics:
    _target_: cargpt.components.objectives.ForwardDynamicsPredictionObjective
    depth_decoder:
      _target_: cargpt.components.disparity.DepthDecoder
      # num_ch_enc: [64, 64, 128, 256, 512] # resnet < 34
      # num_ch_enc: [64, 256, 512, 1024, 2048] # resnet > 34
      num_ch_enc: [64, 256, 512, 1024, 2048] # resnet > 34
      scales: [0]
      num_output_channels: 1
      use_skips: true

    pose_decoder:
      _target_: torch.nn.Linear
      in_features:
        _target_: operator.mul
        _args_:
          - 2
          - ${vars.embedding_dim}
      out_features: 6

    pose_labeler:
      _target_: cargpt.components.pose.SpeedPoseLabeler

    heads:
      _target_: cargpt.utils.ModuleDict
      image:
        cam_front_left:
          _target_: torch.nn.Linear
          in_features:
            _target_: operator.mul
            _args_:
              - 3
              - ${vars.embedding_dim}
          out_features: ${vars.embedding_dim}
          bias: False
      continuous:
        speed:
          _target_: torch.nn.Linear
          in_features:
            _target_: operator.mul
            _args_:
              - 3
              - ${vars.embedding_dim}
          out_features: ${model.episode_builder.tokenizers.continuous.speed.bins}
          bias: False
      discrete:
        turn_signal:
          _target_: torch.nn.Linear
          in_features:
            _target_: operator.mul
            _args_:
              - 3
              - ${vars.embedding_dim}
          out_features: ${model.episode_builder.embeddings.discrete.turn_signal.num_embeddings}
          bias: False
    targets:
      image:
        cam_front_left:
          _target_: cargpt.components.episode.Episode.get
          _partial_: true
          key: ["embedded_nope", "image", "cam_front_left"]
      continuous:
        speed:
          _target_: cargpt.components.episode.Episode.get
          _partial_: true
          key: ["tokenized", "continuous", "speed"]
      discrete:
        turn_signal:
          _target_: cargpt.components.episode.Episode.get
          _partial_: true
          key: ["tokenized", "discrete", "turn_signal"]
    losses:
      _target_: cargpt.utils.ModuleDict
      image:
        cam_front_left:
          _target_: torch.nn.MSELoss
          reduction: mean
      continuous:
        speed:
          _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      discrete:
        turn_signal:
          _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      depth:
        photogeometry:
          cam_front_left:
            _target_: cargpt.components.loss.PhotoGeometryLoss
            with_ssim: true
            with_mask: true
            with_auto_mask: true
            weight_photometric: 1.0
            weight_geometric: 0.5
        pose:
          cam_front_left:
            _target_: cargpt.components.pose.TranslationNormPoseLoss
        smoothness:
          cam_front_left:
            _target_: cargpt.components.loss.SmoothnessLoss

      # random_masked_hindsight_control:
      #   _target_: cargpt.components.objectives.RandomMaskedHindsightControlObjective
      #   heads:
      #     _target_: cargpt.utils.ModuleDict
      #     continuous:
      #       gas_pedal:
      #         _target_: torch.nn.Linear
      #         in_features: ${vars.embedding_dim}
      #         out_features: ${model.episode_builder.tokenizers.continuous.gas_pedal.bins}
      #         bias: False
      #       brake_pedal:
      #         _target_: torch.nn.Linear
      #         in_features: ${vars.embedding_dim}
      #         out_features: ${model.episode_builder.tokenizers.continuous.brake_pedal.bins}
      #         bias: False
      #       steering_angle:
      #         _target_: torch.nn.Linear
      #         in_features: ${vars.embedding_dim}
      #         out_features: ${model.episode_builder.tokenizers.continuous.steering_angle.bins}
      #         bias: False
      #   targets:
      #     continuous:
      #       gas_pedal:
      #         _target_: cargpt.components.episode.Episode.get
      #         _partial_: true
      #         key: ["tokenized", "continuous", "gas_pedal"]
      #       brake_pedal:
      #         _target_: cargpt.components.episode.Episode.get
      #         _partial_: true
      #         key: ["tokenized", "continuous", "brake_pedal"]
      #       steering_angle:
      #         _target_: cargpt.components.episode.Episode.get
      #         _partial_: true
      #         key: ["tokenized", "continuous", "steering_angle"]
      #   losses:
      #     _target_: cargpt.utils.ModuleDict
      #     continuous:
      #       gas_pedal:
      #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      #       brake_pedal:
      #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      #       steering_angle:
      #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      # memory_extraction:
      #   _target_: cargpt.components.objectives.MemoryExtractionObjective
      #   heads:
      #     _target_: cargpt.utils.ModuleDict
      #     continuous:
      #       gas_pedal:
      #         _target_: torch.nn.Linear
      #         in_features: ${vars.embedding_dim}
      #         out_features: ${model.objectives.memory_extraction.delta_tokenizers.continuous.gas_pedal.quantization_channels}
      #         bias: False
      #       brake_pedal:
      #         _target_: torch.nn.Linear
      #         in_features: ${vars.embedding_dim}
      #         out_features: ${model.objectives.memory_extraction.delta_tokenizers.continuous.brake_pedal.quantization_channels}
      #         bias: False
      #       steering_angle:
      #         _target_: torch.nn.Linear
      #         in_features: ${vars.embedding_dim}
      #         out_features: ${model.objectives.memory_extraction.delta_tokenizers.continuous.steering_angle._args_[1].quantization_channels}
      #         bias: False
      #   targets:
      #     continuous:
      #       gas_pedal:
      #         _target_: cargpt.components.episode.Episode.get
      #         _partial_: true
      #         key: ["inputs", "continuous", "gas_pedal"]
      #       brake_pedal:
      #         _target_: cargpt.components.episode.Episode.get
      #         _partial_: true
      #         key: ["inputs", "continuous", "brake_pedal"]
      #       steering_angle:
      #         _target_: cargpt.components.episode.Episode.get
      #         _partial_: true
      #         key: ["inputs", "continuous", "steering_angle"]
      #   losses:
      #     _target_: cargpt.utils.ModuleDict
      #     continuous:
      #       gas_pedal:
      #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      #       brake_pedal:
      #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      #       steering_angle:
      #         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
      #   delta_tokenizers:
      #     _target_: cargpt.utils.ModuleDict
      #     continuous:
      #       gas_pedal:
      #         # NOTE: no pre-mulaw scaling since if x in [0.0, 1.0] then dx in [-1.0, 1.0]
      #         _target_: cargpt.components.norm.MuLawEncoding
      #         quantization_channels: ${vars.embedding_dim}
      #       brake_pedal:
      #         # NOTE: no pre-mulaw scaling since if x in [0.0, 1.0] then dx in [-1.0, 1.0]
      #         _target_: cargpt.components.norm.MuLawEncoding
      #         quantization_channels: ${vars.embedding_dim}
      #       steering_angle:
      #         _target_: cargpt.components.nn.Sequential
      #         _args_:
      #           - _target_: cargpt.components.norm.Scaler
      #             in_range: [-2.0, 2.0]
      #             out_range: [-1.0, 1.0]
      #           - _target_: cargpt.components.norm.MuLawEncoding
      #             quantization_channels: ${vars.embedding_dim}
# policy:
#   _target_: cargpt.components.objectives.PolicyObjective
#   heads:
#     _target_: cargpt.utils.ModuleDict
#     continuous:
#       gas_pedal:
#         _target_: torch.nn.Linear
#         in_features:
#           _target_: operator.mul
#           _args_:
#             - 2
#             - ${vars.embedding_dim}
#         out_features: ${model.episode_builder.tokenizers.continuous.gas_pedal.bins}
#         bias: False
#       brake_pedal:
#         _target_: torch.nn.Linear
#         in_features:
#           _target_: operator.mul
#           _args_:
#             - 2
#             - ${vars.embedding_dim}
#         out_features: ${model.episode_builder.tokenizers.continuous.brake_pedal.bins}
#         bias: False

#       steering_angle:
#         _target_: torch.nn.Linear
#         in_features:
#           _target_: operator.mul
#           _args_:
#             - 2
#             - ${vars.embedding_dim}
#         out_features: ${model.episode_builder.tokenizers.continuous.steering_angle.bins}
#         bias: False

#   losses:
#     _target_: cargpt.utils.ModuleDict
#     continuous:
#       gas_pedal:
#         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss

#       brake_pedal:
#         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss

#       steering_angle:
#         _target_: cargpt.components.loss.LogitBiasCrossEntropyLoss
# objective_scheduler:
#   _target_: cargpt.components.objectives.ObjectiveScheduler
#   schedule:
#     inverse_dynamics: 0.25
#     forward_dynamics: 0.25
#     random_masked_hindsight_control: 0.25
#     memory_extraction: 0.25
#   sample_size: 1
optimizer:
  _target_: cargpt.components.optimizers.SelectiveAdamW
  _recursive_: true
  lr: 1e-6
  betas: [0.9, 0.95]
  weight_decay: 0.1
  weight_decay_module_blacklist:
    - _target_: hydra.utils.get_class
      path: torch.nn.Embedding
    - _target_: hydra.utils.get_class
      path: torch.nn.LayerNorm
lr_scheduler:
  interval: step
  # scheduler:
  #   # TODO: this is like 5 lines -- reimplement and drop transformers dep?
  #   _target_: transformers.get_cosine_schedule_with_warmup
  #   num_warmup_steps: 25000
  #   num_training_steps: 250000
  scheduler:
    _target_: torch.optim.lr_scheduler.CyclicLR
    base_lr: 1e-6
    max_lr: 1e-4
    step_size_up: 10000
    mode: triangular
    cycle_momentum: false # https://github.com/pytorch/pytorch/issues/90414

