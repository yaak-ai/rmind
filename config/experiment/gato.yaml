# @package _global_

defaults:
  - /paths: default
  - override /datamodule: gato.yaml
  - _self_

wandb:
  group: Gato-speed-to-speed

d_model: 512

batch_size: 24
clip_len: 48
frame_mask: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
cont_values_bins: 2048
shift_discrete: 3  # for separator, start and end token
num_discrete_cont: 2051  # cont_values_bins + shift_discrete
embedding_dim: 768


model:
  _target_: cargpt.models.gato.Gato
  _recursive_: False

  optimizer:
    _target_: torch.optim.Adam
    lr: 1e-4
    weight_decay: 0

  encodings:
    _target_: torch.nn.ModuleDict
    modules:
      continues_values:
        _target_: torch.nn.Sequential
        _args_:
          - _target_: cargpt.models.encoding.MuLawCompressor
            mu: 100  # how steppy is the function
            M: 256  # value of x that y = -1 / y = 1
          - _target_: cargpt.models.encoding.Discretizer
            range_min: -1.0
            range_max: 1.0
            start_index: ${shift_discrete}
            bins: ${cont_values_bins}  # 1024: bin width is 0.001953125 ~= 0.002

  embeddings:
    discrete_embedding:
      _target_: torch.nn.Embedding
      num_embeddings: ${num_discrete_cont}
      embedding_dim: ${embedding_dim}
      padding_idx: 0  # for separator
    local_position:
      _target_: torch.nn.Embedding
      num_embeddings: ${clip_len}
      embedding_dim: ${embedding_dim}
    action_position:
      _target_: torch.nn.Embedding
      num_embeddings: 1
      embedding_dim: ${embedding_dim}

  transformer_decoder:
    _target_: torch.nn.TransformerDecoder
    num_layers: 8
    decoder_layer:
      _target_: cargpt.models.gato.TransformerDecoderLayerGEGLU
      d_model: ${embedding_dim}
      dim_feedforward: 3072
      nhead: 16
      dropout: 0.1
      batch_first: True
      norm_first: True
  back_to_discrete:
    _target_: torch.nn.Linear
    in_features: ${embedding_dim}
    out_features: ${cont_values_bins}

  log:
    validation:
      outputs: true

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  devices: [0]
  benchmark: true
  max_steps: 100000
  log_every_n_steps: 1

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    log_model: true

  callbacks:
    - _target_: cargpt.callbacks.ModelSummary
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      save_weights_only: True
      save_on_train_epoch_end: True
      monitor: train/loss

datamodule:
  train:
    batch_size: ${batch_size}
    dataset:
      config:
        samples:
          clips:
            length: ${clip_len}
            stride: 5
            step: 5
            frame_mask: ${frame_mask}
  val:
    batch_size: ${batch_size}
    dataset:
      config:
        samples:
          clips:
            length: ${clip_len}
            stride: 5
            step: 5
            frame_mask: ${frame_mask}
