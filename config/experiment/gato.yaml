# @package _global_

defaults:
  - /paths: default
  - override /datamodule: gato.yaml
  - _self_

wandb:
  group: Gato-speed-to-speed

d_model: 512

batch_size: 4
clip_len: 192
predict_clips_len: 48  # tail from clip_len
cont_values_bins: 1024
embedding_dim: 768

model:
  _target_: cargpt.models.gato.Gato
  _recursive_: False

  optimizer:
    _target_: torch.optim.Adam
    lr: 1e-4
    weight_decay: 0

  encodings:
    _target_: torch.nn.ModuleDict
    modules:
      continues_values:
        _target_: torch.nn.Sequential
        _args_:
          - _target_: cargpt.models.encoding.MuLawCompressor
            mu: 100  # how steppy is the function
            M: 256  # value of x that y = -1 / y = 1
          - _target_: cargpt.models.encoding.Discretizer
            range_min: -1.0
            range_max: 1.0
            start_index: 0
            bins: ${cont_values_bins}  # 1024: bin width is 0.001953125 ~= 0.002

  embeddings:
    discrete_cont_embedding:
      _target_: torch.nn.Embedding
      num_embeddings: ${cont_values_bins}
      embedding_dim: ${embedding_dim}
    local_position:
      _target_: torch.nn.Embedding
      num_embeddings: ${clip_len}
      embedding_dim: ${embedding_dim}
    action_position:
      _target_: torch.nn.Embedding
      num_embeddings: 1
      embedding_dim: ${embedding_dim}

  transformer_decoder:
    _target_: torch.nn.TransformerDecoder
    num_layers: 8
    decoder_layer:
      _target_: cargpt.models.gato.TransformerDecoderLayerGEGLU
      d_model: ${embedding_dim}
      dim_feedforward: 3072
      nhead: 16
      dropout: 0.1
      batch_first: True
      norm_first: True
  back_to_discrete:
    _target_: torch.nn.Linear
    in_features: ${embedding_dim}
    out_features: ${cont_values_bins}

  predict_steps: ${predict_clips_len}

  log:
    validation:
      outputs: true

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  devices: [0]
  benchmark: true
  max_steps: 100000
  log_every_n_steps: 1

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    log_model: false

datamodule:
  train:
    batch_size: ${batch_size}
    dataset:
      config:
        samples:
          clips:
            length: ${clip_len}
            stride: 5
            step: 5
            frame_mask: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
  val:
    batch_size: ${batch_size}
    dataset:
      config:
        samples:
          clips:
            length: ${clip_len}
            stride: 5
            step: 5
            frame_mask: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
