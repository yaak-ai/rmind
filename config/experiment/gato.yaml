# @package _global_

defaults:
  - /paths: default
  - override /datamodule: gato.yaml
  - _self_

wandb:
  group: Gato-Image-speed-to-control

batch_size: 1
clip_len: 16
cont_values_bins: 1024
shift_discrete: 3  # for special_tokens
num_discrete_cont: 1027  # cont_values_bins + shift_discrete
metadata_keys: ["VehicleMotion_speed"]
action_keys: ["VehicleMotion_gas_pedal_normalized"]
patch_row_bins: 10
patch_col_bins: 18
embedding_dim: 512

model:
  _target_: cargpt.models.gato.Gato
  _recursive_: False

  optimizer:
    _target_: torch.optim.Adam
    lr: 1e-4
    weight_decay: 0

  image_encoder:
    _target_: cargpt.models.encoding.ResnetBackbone
    resnet:
      _target_: torchvision.models.resnet18
      weights: IMAGENET1K_V1
    freeze: True

  sensor_tokenizer:
    _target_: torch.nn.ModuleDict
    modules:
      continues:
        _target_: torch.nn.Sequential
        _args_:
          - _target_: cargpt.models.encoding.MuLawCompressor
            mu: 100  # how steppy is the function
            M: 256  # value of x that y = -1 / y = 1
          - _target_: cargpt.models.encoding.Discretizer
            range_min: -1.0
            range_max: 1.0
            start_index: ${shift_discrete}
            bins: ${cont_values_bins}  # 1024: bin width is 0.001953125 ~= 0.002

  sensor_encoder:
    continous:
      _target_: torch.nn.Embedding
      num_embeddings: ${num_discrete_cont}
      embedding_dim: ${embedding_dim}

  position_encoding:
    patch_row:
      _target_: torch.nn.Embedding
      num_embeddings: ${patch_row_bins}
      embedding_dim: ${embedding_dim}
    patch_col:
      _target_: torch.nn.Embedding
      num_embeddings: ${patch_col_bins}
      embedding_dim: ${embedding_dim}
    local:
      _target_: torch.nn.Embedding
      num_embeddings: ${clip_len}
      embedding_dim: ${embedding_dim}
    action:
      _target_: torch.nn.Embedding
      num_embeddings: 1
      embedding_dim: ${embedding_dim}

  transformer_decoder:
    _target_: torch.nn.TransformerDecoder
    num_layers: 8
    decoder_layer:
      _target_: cargpt.models.gato.TransformerDecoderLayerGEGLU
      d_model: ${embedding_dim}
      dim_feedforward: 3072
      nhead: 16
      dropout: 0.1
      batch_first: True
      norm_first: True
  classifier:
    _target_: torch.nn.Linear
    in_features: ${embedding_dim}
    out_features: ${num_discrete_cont}

  metadata_keys: ${metadata_keys}
  action_keys: ${action_keys}
  special_tokens:
    bos: 0
    sep: 1
    eos: 2
  masks:
    image: -1 # to ignore_index in torch.nn.functional.cross_entropy
    metadata: 1
    action: 1
  log:
    validation:
      outputs: true

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  devices: [0]
  benchmark: true
  max_steps: 100000
  log_every_n_steps: 1

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    log_model: true

  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      save_weights_only: True
      save_on_train_epoch_end: True
      monitor: train/loss

datamodule:
  train:
    batch_size: ${batch_size}
    dataset:
      config:
        samples:
          clips:
            length: ${clip_len}
            stride: 5
            step: 5

  val:
    batch_size: ${batch_size}
    dataset:
      config:
        samples:
          clips:
            length: ${clip_len}
            stride: 5
            step: 5
